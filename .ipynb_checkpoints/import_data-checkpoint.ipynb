{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6465e9d1-6ab8-4b9d-8393-2edf5db7de70",
   "metadata": {},
   "source": [
    "<h1><b> Set-up to Import the Spotify Dataset to MySQL Workbench! </b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f28ce-8f39-4a6c-9028-159bfd289b07",
   "metadata": {},
   "source": [
    "<H3><b>Install Necessary Libraries</b></H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596ad138-6003-4f69-869f-addffabb29f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\anaconda\\lib\\site-packages (9.2.0)\n",
      "Requirement already satisfied: pandas in c:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: gdown in c:\\anaconda\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\anaconda\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\anaconda\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\anaconda\\lib\\site-packages (from gdown) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from gdown) (4.66.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\anaconda\\lib\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (2024.7.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python pandas gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec22921-c701-42ea-8255-42722ad91d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 30.7/45.0 kB 640.0 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 30.7/45.0 kB 640.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/45.0 kB 245.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/45.0 kB 245.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/45.0 kB 245.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.0/45.0 kB 147.8 kB/s eta 0:00:00\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c62415-79b1-4c33-9a51-b2f4164ce93e",
   "metadata": {},
   "source": [
    "<H3><b>Import Data</b></H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be424e0e-8ae2-4ae7-9733-0be135c4f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import gdown\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from pymysql import OperationalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc3d1f7e-4b8d-4231-a82c-b87aea0c195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u\n",
      "To: C:\\Users\\Richard Muchoki\\Documents\\SQL\\Spotify_Dataset_Analysis\\spotify_dataset.csv\n",
      "100%|██████████| 21.3M/21.3M [01:03<00:00, 337kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spotify_dataset.csv'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Download the dataset from Google Drive\n",
    "file_id = '1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u'\n",
    "output = 'spotify_dataset.csv'\n",
    "gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab354a-96d7-41eb-a83b-628e62013903",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\"><b>Note:</b><br>\n",
    "    \n",
    "    ** From the shareable link, extract the file ID. The file ID is the part after /d/ and before /view. **\n",
    "\n",
    "<b>For example, if your link is:</b>\n",
    "\n",
    "<spam>https://drive.google.com/file/d/1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u/view?usp=drive_link</spam>\n",
    "\n",
    "The file ID is <b>1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u.</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2d340d8-1d26-4b17-abb8-a7112c4e1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b0423ec-e6f7-4961-94d1-5833019ef4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        spotify_track_uri                   ts    platform  ms_played  \\\n",
      "0  2J3n32GeLmMjwuAzyhcSNe  2013-07-08 02:44:34  web player       3185   \n",
      "1  1oHxIPqJyvAYHy0PVrDU98  2013-07-08 02:45:37  web player      61865   \n",
      "2  487OPlneJNni3NWC8SYqhW  2013-07-08 02:50:24  web player     285386   \n",
      "3  5IyblF777jLZj1vGHG2UD3  2013-07-08 02:52:40  web player     134022   \n",
      "4  0GgAAB0ZMllFhbNc3mAodO  2013-07-08 03:17:52  web player          0   \n",
      "\n",
      "                                      track_name        artist_name  \\\n",
      "0                            Say It, Just Say It       The Mowgli's   \n",
      "1  Drinking from the Bottle (feat. Tinie Tempah)      Calvin Harris   \n",
      "2                                    Born To Die       Lana Del Rey   \n",
      "3                               Off To The Races       Lana Del Rey   \n",
      "4                                      Half Mast  Empire Of The Sun   \n",
      "\n",
      "                           album_name reason_start reason_end  shuffle  \\\n",
      "0                Waiting For The Dawn     autoplay   clickrow    False   \n",
      "1                           18 Months     clickrow   clickrow    False   \n",
      "2  Born To Die - The Paradise Edition     clickrow    unknown    False   \n",
      "3  Born To Die - The Paradise Edition    trackdone   clickrow    False   \n",
      "4                  Walking On A Dream     clickrow    nextbtn    False   \n",
      "\n",
      "   skipped  \n",
      "0    False  \n",
      "1    False  \n",
      "2    False  \n",
      "3    False  \n",
      "4    False  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame to confirm successful loading\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41d20c05-be1d-4740-95dd-93843ed75fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149860, 11)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows and columns respectively\n",
    "# Initial output: 149,860 rows and 11 columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f25c34e-b030-4608-9363-63eab5973a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Handle NaN values by replacing them with appropriate defaults\n",
    "df.fillna({\n",
    "    'spotify_track_uri': '',\n",
    "    'ts': '1970-01-01 00:00:00',\n",
    "    'platform': '',\n",
    "    'ms_played': 0,\n",
    "    'track_name': '',\n",
    "    'artist_name': '',\n",
    "    'album_name': '',\n",
    "    'reason_start': '',\n",
    "    'reason_end': '',\n",
    "    'shuffle': False,\n",
    "    'skipped': False\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4be96fd9-8444-447d-afe9-b362ef455275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             spotify_track_uri                   ts platform  ms_played  \\\n",
      "1179    3U4isOIWM3VvDubwSI3y7a  2015-08-29 16:45:52  android       3042   \n",
      "1180    3U4isOIWM3VvDubwSI3y7a  2015-08-29 16:45:52  android       4179   \n",
      "1533    6y63IkVtjr2RnPVvK8BqEj  2015-09-01 05:05:18  windows        333   \n",
      "1535    6y63IkVtjr2RnPVvK8BqEj  2015-09-01 05:05:18  android       1531   \n",
      "1659    3fWNnzF9L1z5m8LJ3UJREV  2015-09-10 02:37:21  android       2547   \n",
      "...                        ...                  ...      ...        ...   \n",
      "125713  4401c08DdNwwGEg8WGCkQf  2022-10-01 23:18:48  android       1611   \n",
      "125760  0LxCY6cjKgjutOZaqyjrVQ  2022-10-02 18:34:27  android     221693   \n",
      "125761  0LxCY6cjKgjutOZaqyjrVQ  2022-10-02 18:34:27  android     221693   \n",
      "126078  21s2FWRApO7LxvhunUoPNm  2022-10-10 06:00:48  android       1794   \n",
      "126079  21s2FWRApO7LxvhunUoPNm  2022-10-10 06:00:48  android     186549   \n",
      "\n",
      "                                track_name  artist_name  \\\n",
      "1179                             All of Me  John Legend   \n",
      "1180                             All of Me  John Legend   \n",
      "1533                               Paraíso       Dvicio   \n",
      "1535                               Paraíso       Dvicio   \n",
      "1659                          En Cambio Tu  Par de Ases   \n",
      "...                                    ...          ...   \n",
      "125713  Paperback Writer - Remastered 2009  The Beatles   \n",
      "125760             Hombre de ninguna parte   Xoel López   \n",
      "125761             Hombre de ninguna parte   Xoel López   \n",
      "126078                             My Mind       Skegss   \n",
      "126079                             My Mind       Skegss   \n",
      "\n",
      "                                   album_name reason_start reason_end  \\\n",
      "1179    Love In The Future (Expanded Edition)      appload    endplay   \n",
      "1180    Love In The Future (Expanded Edition)     clickrow    endplay   \n",
      "1533                                  Paraíso      appload    endplay   \n",
      "1535                                  Paraíso      appload    endplay   \n",
      "1659                        Te Quiero a Morir     clickrow    endplay   \n",
      "...                                       ...          ...        ...   \n",
      "125713                           Past Masters       fwdbtn     fwdbtn   \n",
      "125760                              Atlántico       fwdbtn  trackdone   \n",
      "125761                              Atlántico       fwdbtn  trackdone   \n",
      "126078                            My Own Mess      appload  trackdone   \n",
      "126079                            My Own Mess    trackdone     logout   \n",
      "\n",
      "        shuffle  skipped  \n",
      "1179       True     True  \n",
      "1180       True     True  \n",
      "1533      False     True  \n",
      "1535      False     True  \n",
      "1659       True     True  \n",
      "...         ...      ...  \n",
      "125713     True    False  \n",
      "125760     True    False  \n",
      "125761     True    False  \n",
      "126078     True    False  \n",
      "126079     True    False  \n",
      "\n",
      "[2870 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates and print them for the unique identifiers of our data\n",
    "duplicates = df[df.duplicated(subset=['spotify_track_uri', 'ts'], keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b2463c7-aa6d-4d07-a584-9561281c7f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of duplicates: 1.92%\n"
     ]
    }
   ],
   "source": [
    "# let's measure the extent of duplicates\n",
    "# Calculate the percentage of exact duplicates\n",
    "total_records = df.shape[0]\n",
    "duplicate_records = duplicates.shape[0]\n",
    "percentage_duplicates = (duplicate_records / total_records) * 100\n",
    "print(f\"Percentage of duplicates: {percentage_duplicates:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a9fd144-3681-47a4-b9db-92a4b80639d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics with duplicates:\n",
      "          ms_played\n",
      "count  1.498600e+05\n",
      "mean   1.283166e+05\n",
      "std    1.178401e+05\n",
      "min    0.000000e+00\n",
      "25%    2.795000e+03\n",
      "50%    1.388400e+05\n",
      "75%    2.185070e+05\n",
      "max    1.561125e+06\n",
      "Statistics without duplicates:\n",
      "          ms_played\n",
      "count  1.486750e+05\n",
      "mean   1.280607e+05\n",
      "std    1.178178e+05\n",
      "min    0.000000e+00\n",
      "25%    2.786000e+03\n",
      "50%    1.383860e+05\n",
      "75%    2.183330e+05\n",
      "max    1.561125e+06\n"
     ]
    }
   ],
   "source": [
    "# Analyze the Impact of Duplicates\n",
    "# Compare statistics with and without duplicates\n",
    "print(\"Statistics with duplicates:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Remove exact duplicates\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "print(\"Statistics without duplicates:\")\n",
    "print(df_no_duplicates.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41504f1d-86ec-40b8-96bb-0a58715a46f2",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\"><b> The duplicates have no significant effect on the statistics hence we can safely drop them </b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed5741e4-fb25-4b5e-a833-0a14d17eba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Remove duplicate entries based on the primary key\n",
    "df.drop_duplicates(subset=['spotify_track_uri', 'ts'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6defbc99-9672-4087-8478-863924a072cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Convert DataFrame to list of tuples for bulk insert\n",
    "data = df.to_records(index=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "702e9602-1fed-4815-8f04-3e68d143f753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the database\n",
      "Table created successfully\n",
      "Data inserted successfully\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Connect to the MySQL database\n",
    "try:\n",
    "    connection = pymysql.connect(\n",
    "        host='localhost',      # Replace with your MySQL host\n",
    "        user='root',  # Replace with your MySQL username\n",
    "        password='12345678',  # Replace with your MySQL password\n",
    "        database='spotify_analysis'  # Replace with your MySQL database name\n",
    "    )\n",
    "    if connection.open:\n",
    "        print(\"Successfully connected to the database\")\n",
    "        \n",
    "        # Step 8: Create a cursor object\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Step 9: Create a table to store the dataset\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS spotify_data (\n",
    "            spotify_track_uri VARCHAR(255),\n",
    "            ts TIMESTAMP,\n",
    "            platform VARCHAR(255),\n",
    "            ms_played INT,\n",
    "            track_name VARCHAR(255),\n",
    "            artist_name VARCHAR(255),\n",
    "            album_name VARCHAR(255),\n",
    "            reason_start VARCHAR(255),\n",
    "            reason_end VARCHAR(255),\n",
    "            shuffle BOOLEAN,\n",
    "            skipped BOOLEAN,\n",
    "            PRIMARY KEY (spotify_track_uri, ts)\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        print(\"Table created successfully\")\n",
    "\n",
    "         # Step 10: Define the bulk insert query\n",
    "        insert_query = \"\"\"\n",
    "        INSERT IGNORE INTO spotify_data (\n",
    "            spotify_track_uri, ts, platform, ms_played, track_name, artist_name, album_name, reason_start, reason_end, shuffle, skipped\n",
    "        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 11: Perform bulk insert\n",
    "        cursor.executemany(insert_query, data)\n",
    "\n",
    "        # Commit the transaction\n",
    "        connection.commit()\n",
    "        print(\"Data inserted successfully\")\n",
    "\n",
    "\n",
    "except OperationalError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    if connection and connection.open:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c4bdb-a76c-4a2b-a810-a272cdb60510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
