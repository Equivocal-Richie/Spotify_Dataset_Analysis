{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6465e9d1-6ab8-4b9d-8393-2edf5db7de70",
   "metadata": {},
   "source": [
    "<h1><b> Set-up to Import the Spotify Dataset to MySQL Workbench! </b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f28ce-8f39-4a6c-9028-159bfd289b07",
   "metadata": {},
   "source": [
    "<H3><b>Install Necessary Libraries</b></H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596ad138-6003-4f69-869f-addffabb29f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\anaconda\\lib\\site-packages (9.2.0)\n",
      "Requirement already satisfied: pandas in c:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: gdown in c:\\anaconda\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\anaconda\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\anaconda\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\anaconda\\lib\\site-packages (from gdown) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from gdown) (4.66.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\anaconda\\lib\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (2024.7.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python pandas gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec22921-c701-42ea-8255-42722ad91d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 30.7/45.0 kB 640.0 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 30.7/45.0 kB 640.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/45.0 kB 245.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/45.0 kB 245.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/45.0 kB 245.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.0/45.0 kB 147.8 kB/s eta 0:00:00\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c62415-79b1-4c33-9a51-b2f4164ce93e",
   "metadata": {},
   "source": [
    "<H3><b>Import Data</b></H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be424e0e-8ae2-4ae7-9733-0be135c4f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import gdown\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from pymysql import OperationalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc3d1f7e-4b8d-4231-a82c-b87aea0c195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u\n",
      "To: C:\\Users\\Richard Muchoki\\Documents\\SQL\\Spotify_Dataset_Analysis\\spotify_dataset.csv\n",
      "100%|██████████| 21.3M/21.3M [00:36<00:00, 583kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spotify_dataset.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Download the dataset from Google Drive\n",
    "file_id = '1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u'output = 'spotify_dataset.csv'\n",
    "gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "902767e0-da51-4a5c-9213-d81470025cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 'spotify_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab354a-96d7-41eb-a83b-628e62013903",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\"><b>Note:</b><br>\n",
    "    \n",
    "    ** From the shareable link, extract the file ID. The file ID is the part after /d/ and before /view. **\n",
    "\n",
    "<b>For example, if your link is:</b>\n",
    "\n",
    "<spam>https://drive.google.com/file/d/1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u/view?usp=drive_link</spam>\n",
    "\n",
    "The file ID is <b>1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u.</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2d340d8-1d26-4b17-abb8-a7112c4e1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0423ec-e6f7-4961-94d1-5833019ef4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        spotify_track_uri                   ts    platform  ms_played  \\\n",
      "0  2J3n32GeLmMjwuAzyhcSNe  2013-07-08 02:44:34  web player       3185   \n",
      "1  1oHxIPqJyvAYHy0PVrDU98  2013-07-08 02:45:37  web player      61865   \n",
      "2  487OPlneJNni3NWC8SYqhW  2013-07-08 02:50:24  web player     285386   \n",
      "3  5IyblF777jLZj1vGHG2UD3  2013-07-08 02:52:40  web player     134022   \n",
      "4  0GgAAB0ZMllFhbNc3mAodO  2013-07-08 03:17:52  web player          0   \n",
      "\n",
      "                                      track_name        artist_name  \\\n",
      "0                            Say It, Just Say It       The Mowgli's   \n",
      "1  Drinking from the Bottle (feat. Tinie Tempah)      Calvin Harris   \n",
      "2                                    Born To Die       Lana Del Rey   \n",
      "3                               Off To The Races       Lana Del Rey   \n",
      "4                                      Half Mast  Empire Of The Sun   \n",
      "\n",
      "                           album_name reason_start reason_end  shuffle  \\\n",
      "0                Waiting For The Dawn     autoplay   clickrow    False   \n",
      "1                           18 Months     clickrow   clickrow    False   \n",
      "2  Born To Die - The Paradise Edition     clickrow    unknown    False   \n",
      "3  Born To Die - The Paradise Edition    trackdone   clickrow    False   \n",
      "4                  Walking On A Dream     clickrow    nextbtn    False   \n",
      "\n",
      "   skipped  \n",
      "0    False  \n",
      "1    False  \n",
      "2    False  \n",
      "3    False  \n",
      "4    False  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame to confirm successful loading\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41d20c05-be1d-4740-95dd-93843ed75fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149860, 11)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows and columns respectively\n",
    "# Initial output: 149,860 rows and 11 columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f25c34e-b030-4608-9363-63eab5973a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Handle NaN values by replacing them with appropriate defaults\n",
    "df.fillna({\n",
    "    'spotify_track_uri': '',\n",
    "    'ts': '1970-01-01 00:00:00',\n",
    "    'platform': '',\n",
    "    'ms_played': 0,\n",
    "    'track_name': '',\n",
    "    'artist_name': '',\n",
    "    'album_name': '',\n",
    "    'reason_start': '',\n",
    "    'reason_end': '',\n",
    "    'shuffle': False,\n",
    "    'skipped': False\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c424b57-452f-4fe2-8dba-be69d3f846f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Remove duplicate entries based on the primary key\n",
    "df.drop_duplicates(subset=['spotify_track_uri', 'ts'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95df375a-3ad4-4869-b61a-d6a81ef6a517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148350, 11)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6defbc99-9672-4087-8478-863924a072cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Convert DataFrame to list of tuples for bulk insert\n",
    "data = df.to_records(index=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "702e9602-1fed-4815-8f04-3e68d143f753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the database\n",
      "Table created successfully\n",
      "Data inserted successfully\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Connect to the MySQL database\n",
    "try:\n",
    "    connection = pymysql.connect(\n",
    "        host='localhost',      # Replace with your MySQL host\n",
    "        user='root',  # Replace with your MySQL username\n",
    "        password='12345678',  # Replace with your MySQL password\n",
    "        database='spotify_analysis'  # Replace with your MySQL database name\n",
    "    )\n",
    "    if connection.open:\n",
    "        print(\"Successfully connected to the database\")\n",
    "        \n",
    "        # Step 8: Create a cursor object\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Step 9: Create a table to store the dataset\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS spotify_data (\n",
    "            spotify_track_uri VARCHAR(255),\n",
    "            ts TIMESTAMP,\n",
    "            platform VARCHAR(255),\n",
    "            ms_played INT,\n",
    "            track_name VARCHAR(255),\n",
    "            artist_name VARCHAR(255),\n",
    "            album_name VARCHAR(255),\n",
    "            reason_start VARCHAR(255),\n",
    "            reason_end VARCHAR(255),\n",
    "            shuffle BOOLEAN,\n",
    "            skipped BOOLEAN,\n",
    "            PRIMARY KEY (spotify_track_uri, ts)\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        print(\"Table created successfully\")\n",
    "\n",
    "         # Step 10: Define the bulk insert query\n",
    "        insert_query = \"\"\"\n",
    "        INSERT IGNORE INTO spotify_data (\n",
    "            spotify_track_uri, ts, platform, ms_played, track_name, artist_name, album_name, reason_start, reason_end, shuffle, skipped\n",
    "        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 11: Perform bulk insert\n",
    "        cursor.executemany(insert_query, data)\n",
    "\n",
    "        # Commit the transaction\n",
    "        connection.commit()\n",
    "        print(\"Data inserted successfully\")\n",
    "\n",
    "\n",
    "except OperationalError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    if connection and connection.open:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c4bdb-a76c-4a2b-a810-a272cdb60510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
