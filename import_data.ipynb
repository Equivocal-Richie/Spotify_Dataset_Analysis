{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6465e9d1-6ab8-4b9d-8393-2edf5db7de70",
   "metadata": {},
   "source": [
    "<h1><b> Set-up to Import the Spotify Dataset to MySQL Workbench! </b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f28ce-8f39-4a6c-9028-159bfd289b07",
   "metadata": {},
   "source": [
    "<H3><b>1. Install Necessary Libraries</b></H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596ad138-6003-4f69-869f-addffabb29f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\anaconda\\lib\\site-packages (9.2.0)\n",
      "Requirement already satisfied: pandas in c:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: gdown in c:\\anaconda\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\anaconda\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\anaconda\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\anaconda\\lib\\site-packages (from gdown) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from gdown) (4.66.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\anaconda\\lib\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (2024.7.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\anaconda\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python pandas gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec22921-c701-42ea-8255-42722ad91d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 30.7/45.0 kB 640.0 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 30.7/45.0 kB 640.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/45.0 kB 245.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/45.0 kB 245.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/45.0 kB 245.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.0/45.0 kB 147.8 kB/s eta 0:00:00\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d63a89e-f248-48d3-b21a-f42f4c5d6d71",
   "metadata": {},
   "source": [
    "<h3><b> 2. Download the dataset from Google Drive and Directly Load it to MySQL </b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab354a-96d7-41eb-a83b-628e62013903",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\"><b>Note:</b><br>\n",
    "Extract the File ID:\n",
    "    ** From the shareable link, extract the file ID. The file ID is the part after /d/ and before /view. **\n",
    "\n",
    "<b>For example, if your link is:</b>\n",
    "\n",
    "<spam>https://drive.google.com/file/d/1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u/view?usp=drive_link</spam>\n",
    "\n",
    "The file ID is <b>1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u.</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be424e0e-8ae2-4ae7-9733-0be135c4f5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u\n",
      "To: C:\\Users\\Richard Muchoki\\Documents\\SQL\\Spotify_Dataset_Analysis\\spotify_dataset.csv\n",
      "100%|██████████| 21.3M/21.3M [00:37<00:00, 567kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        spotify_track_uri                   ts    platform  ms_played  \\\n",
      "0  2J3n32GeLmMjwuAzyhcSNe  2013-07-08 02:44:34  web player       3185   \n",
      "1  1oHxIPqJyvAYHy0PVrDU98  2013-07-08 02:45:37  web player      61865   \n",
      "2  487OPlneJNni3NWC8SYqhW  2013-07-08 02:50:24  web player     285386   \n",
      "3  5IyblF777jLZj1vGHG2UD3  2013-07-08 02:52:40  web player     134022   \n",
      "4  0GgAAB0ZMllFhbNc3mAodO  2013-07-08 03:17:52  web player          0   \n",
      "\n",
      "                                      track_name        artist_name  \\\n",
      "0                            Say It, Just Say It       The Mowgli's   \n",
      "1  Drinking from the Bottle (feat. Tinie Tempah)      Calvin Harris   \n",
      "2                                    Born To Die       Lana Del Rey   \n",
      "3                               Off To The Races       Lana Del Rey   \n",
      "4                                      Half Mast  Empire Of The Sun   \n",
      "\n",
      "                           album_name reason_start reason_end  shuffle  \\\n",
      "0                Waiting For The Dawn     autoplay   clickrow    False   \n",
      "1                           18 Months     clickrow   clickrow    False   \n",
      "2  Born To Die - The Paradise Edition     clickrow    unknown    False   \n",
      "3  Born To Die - The Paradise Edition    trackdone   clickrow    False   \n",
      "4                  Walking On A Dream     clickrow    nextbtn    False   \n",
      "\n",
      "   skipped  \n",
      "0    False  \n",
      "1    False  \n",
      "2    False  \n",
      "3    False  \n",
      "4    False  \n",
      "Successfully connected to the database\n",
      "Table created successfully\n",
      "Inserted rows 0 to 1000\n",
      "Inserted rows 1000 to 2000\n",
      "Inserted rows 2000 to 3000\n",
      "Inserted rows 3000 to 4000\n",
      "Inserted rows 4000 to 5000\n",
      "Inserted rows 5000 to 6000\n",
      "Inserted rows 6000 to 7000\n",
      "Inserted rows 7000 to 8000\n",
      "Inserted rows 8000 to 9000\n",
      "Inserted rows 9000 to 10000\n",
      "Inserted rows 10000 to 11000\n",
      "Inserted rows 11000 to 12000\n",
      "Inserted rows 12000 to 13000\n",
      "Inserted rows 13000 to 14000\n",
      "Inserted rows 14000 to 15000\n",
      "Inserted rows 15000 to 16000\n",
      "Inserted rows 16000 to 17000\n",
      "Inserted rows 17000 to 18000\n",
      "Inserted rows 18000 to 19000\n",
      "Inserted rows 19000 to 20000\n",
      "Inserted rows 20000 to 21000\n",
      "Inserted rows 21000 to 22000\n",
      "Inserted rows 22000 to 23000\n",
      "Inserted rows 23000 to 24000\n",
      "Inserted rows 24000 to 25000\n",
      "Inserted rows 25000 to 26000\n",
      "Inserted rows 26000 to 27000\n",
      "Inserted rows 27000 to 28000\n",
      "Inserted rows 28000 to 29000\n",
      "Inserted rows 29000 to 30000\n",
      "Inserted rows 30000 to 31000\n",
      "Inserted rows 31000 to 32000\n",
      "Inserted rows 32000 to 33000\n",
      "Inserted rows 33000 to 34000\n",
      "Inserted rows 34000 to 35000\n",
      "Inserted rows 35000 to 36000\n",
      "Inserted rows 36000 to 37000\n",
      "Inserted rows 37000 to 38000\n",
      "Inserted rows 38000 to 39000\n",
      "Inserted rows 39000 to 40000\n",
      "Inserted rows 40000 to 41000\n",
      "Inserted rows 41000 to 42000\n",
      "Inserted rows 42000 to 43000\n",
      "Inserted rows 43000 to 44000\n",
      "Inserted rows 44000 to 45000\n",
      "Inserted rows 45000 to 46000\n",
      "Inserted rows 46000 to 47000\n",
      "Inserted rows 47000 to 48000\n",
      "Inserted rows 48000 to 49000\n",
      "Inserted rows 49000 to 50000\n",
      "Inserted rows 50000 to 51000\n",
      "Inserted rows 51000 to 52000\n",
      "Inserted rows 52000 to 53000\n",
      "Inserted rows 53000 to 54000\n",
      "Inserted rows 54000 to 55000\n",
      "Inserted rows 55000 to 56000\n",
      "Inserted rows 56000 to 57000\n",
      "Inserted rows 57000 to 58000\n",
      "Inserted rows 58000 to 59000\n",
      "Inserted rows 59000 to 60000\n",
      "Inserted rows 60000 to 61000\n",
      "Inserted rows 61000 to 62000\n",
      "Inserted rows 62000 to 63000\n",
      "Inserted rows 63000 to 64000\n",
      "Inserted rows 64000 to 65000\n",
      "Inserted rows 65000 to 66000\n",
      "Inserted rows 66000 to 67000\n",
      "Inserted rows 67000 to 68000\n",
      "Inserted rows 68000 to 69000\n",
      "Inserted rows 69000 to 70000\n",
      "Inserted rows 70000 to 71000\n",
      "Inserted rows 71000 to 72000\n",
      "Inserted rows 72000 to 73000\n",
      "Inserted rows 73000 to 74000\n",
      "Inserted rows 74000 to 75000\n",
      "Inserted rows 75000 to 76000\n",
      "Inserted rows 76000 to 77000\n",
      "Inserted rows 77000 to 78000\n",
      "Inserted rows 78000 to 79000\n",
      "Inserted rows 79000 to 80000\n",
      "Inserted rows 80000 to 81000\n",
      "Inserted rows 81000 to 82000\n",
      "Inserted rows 82000 to 83000\n",
      "Inserted rows 83000 to 84000\n",
      "Inserted rows 84000 to 85000\n",
      "Inserted rows 85000 to 86000\n",
      "Inserted rows 86000 to 87000\n",
      "Inserted rows 87000 to 88000\n",
      "Inserted rows 88000 to 89000\n",
      "Inserted rows 89000 to 90000\n",
      "Inserted rows 90000 to 91000\n",
      "Inserted rows 91000 to 92000\n",
      "Inserted rows 92000 to 93000\n",
      "Inserted rows 93000 to 94000\n",
      "Inserted rows 94000 to 95000\n",
      "Inserted rows 95000 to 96000\n",
      "Inserted rows 96000 to 97000\n",
      "Inserted rows 97000 to 98000\n",
      "Inserted rows 98000 to 99000\n",
      "Inserted rows 99000 to 100000\n",
      "Inserted rows 100000 to 101000\n",
      "Inserted rows 101000 to 102000\n",
      "Inserted rows 102000 to 103000\n",
      "Inserted rows 103000 to 104000\n",
      "Inserted rows 104000 to 105000\n",
      "Inserted rows 105000 to 106000\n",
      "Inserted rows 106000 to 107000\n",
      "Inserted rows 107000 to 108000\n",
      "Inserted rows 108000 to 109000\n",
      "Inserted rows 109000 to 110000\n",
      "Inserted rows 110000 to 111000\n",
      "Inserted rows 111000 to 112000\n",
      "Inserted rows 112000 to 113000\n",
      "Inserted rows 113000 to 114000\n",
      "Inserted rows 114000 to 115000\n",
      "Inserted rows 115000 to 116000\n",
      "Inserted rows 116000 to 117000\n",
      "Inserted rows 117000 to 118000\n",
      "Inserted rows 118000 to 119000\n",
      "Inserted rows 119000 to 120000\n",
      "Inserted rows 120000 to 121000\n",
      "Inserted rows 121000 to 122000\n",
      "Inserted rows 122000 to 123000\n",
      "Inserted rows 123000 to 124000\n",
      "Inserted rows 124000 to 125000\n",
      "Inserted rows 125000 to 126000\n",
      "Inserted rows 126000 to 127000\n",
      "Inserted rows 127000 to 128000\n",
      "Inserted rows 128000 to 129000\n",
      "Inserted rows 129000 to 130000\n",
      "Inserted rows 130000 to 131000\n",
      "Inserted rows 131000 to 132000\n",
      "Inserted rows 132000 to 133000\n",
      "Inserted rows 133000 to 134000\n",
      "Inserted rows 134000 to 135000\n",
      "Inserted rows 135000 to 136000\n",
      "Inserted rows 136000 to 137000\n",
      "Inserted rows 137000 to 138000\n",
      "Inserted rows 138000 to 139000\n",
      "Inserted rows 139000 to 140000\n",
      "Inserted rows 140000 to 141000\n",
      "Inserted rows 141000 to 142000\n",
      "Inserted rows 142000 to 143000\n",
      "Inserted rows 143000 to 144000\n",
      "Inserted rows 144000 to 145000\n",
      "Inserted rows 145000 to 146000\n",
      "Inserted rows 146000 to 147000\n",
      "Inserted rows 147000 to 148000\n",
      "Inserted rows 148000 to 149000\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import gdown\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from pymysql import OperationalError\n",
    "\n",
    "# Step 2: Download the dataset from Google Drive\n",
    "file_id = '1009ZQdqIQV1-TNqNt1rXENK4zFWM_55u'\n",
    "output = 'spotify_dataset.csv'\n",
    "gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=False)\n",
    "\n",
    "# Step 3: Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(output)\n",
    "\n",
    "# Display the first few rows of the DataFrame to confirm successful loading\n",
    "print(df.head())\n",
    "\n",
    "# Step 4: Handle NaN values by replacing them with appropriate defaults\n",
    "df.fillna({\n",
    "    'spotify_track_uri': '',\n",
    "    'ts': '1970-01-01 00:00:00',\n",
    "    'platform': '',\n",
    "    'ms_played': 0,\n",
    "    'track_name': '',\n",
    "    'artist_name': '',\n",
    "    'album_name': '',\n",
    "    'reason_start': '',\n",
    "    'reason_end': '',\n",
    "    'shuffle': False,\n",
    "    'skipped': False\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 5: Remove duplicate entries based on the primary key\n",
    "df.drop_duplicates(subset=['spotify_track_uri', 'ts'], inplace=True)\n",
    "\n",
    "# Step 6: Connect to the MySQL database\n",
    "try:\n",
    "    connection = pymysql.connect(\n",
    "        host='localhost',      # Replace with your MySQL host\n",
    "        user='root',  # Replace with your MySQL username\n",
    "        password='12345678',  # Replace with your MySQL password\n",
    "        database='spotify_analysis'  # Replace with your MySQL database name\n",
    "    )\n",
    "    if connection.open:\n",
    "        print(\"Successfully connected to the database\")\n",
    "        \n",
    "        # Step 7: Create a cursor object\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Step 8: Create a table to store the dataset\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS spotify_data (\n",
    "            spotify_track_uri VARCHAR(255),\n",
    "            ts TIMESTAMP,\n",
    "            platform VARCHAR(255),\n",
    "            ms_played INT,\n",
    "            track_name VARCHAR(255),\n",
    "            artist_name VARCHAR(255),\n",
    "            album_name VARCHAR(255),\n",
    "            reason_start VARCHAR(255),\n",
    "            reason_end VARCHAR(255),\n",
    "            shuffle BOOLEAN,\n",
    "            skipped BOOLEAN,\n",
    "            PRIMARY KEY (spotify_track_uri, ts)\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        print(\"Table created successfully\")\n",
    "\n",
    "        # Step 9: Insert data into the table in chunks, using INSERT IGNORE to handle duplicates\n",
    "        chunk_size = 1000\n",
    "        for start in range(0, len(df), chunk_size):\n",
    "            end = start + chunk_size\n",
    "            chunk = df.iloc[start:end]\n",
    "            for i, row in chunk.iterrows():\n",
    "                insert_query = \"\"\"\n",
    "                INSERT IGNORE INTO spotify_data (spotify_track_uri, ts, platform, ms_played, track_name, artist_name, album_name, reason_start, reason_end, shuffle, skipped)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "            # Commit the transaction after each chunk\n",
    "            connection.commit()\n",
    "            print(f\"Inserted rows {start} to {end}\")\n",
    "\n",
    "except OperationalError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    if connection and connection.open:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41d20c05-be1d-4740-95dd-93843ed75fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148350, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be96fd9-8444-447d-afe9-b362ef455275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
